{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auditing Data Quality Example\n",
    "In this example we work with cities infobox data, audit it, come up with a cleaning idea and then clean it up. Initially, we audit the datatypes that can be found in some particular fields in the dataset. The possible types of values can be:\n",
    "- NoneType if the value is a string \"NULL\" or an empty string \"\"\n",
    "- List, if the value starts with \"{\"\n",
    "- int, if the value can be cast to int\n",
    "- float, if the value can be cast to float, but CANNOT be cast to int.\n",
    "   For example, '3.23e+07' should be considered a float because it can be cast\n",
    "   as float but int('3.23e+07') will throw a ValueError\n",
    "- 'str', for all other values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from zipfile import ZipFile\n",
    "import io\n",
    "import re\n",
    "\n",
    "fname = 'cities.zip'\n",
    "\n",
    "with ZipFile(fname, 'r') as zfile:\n",
    "    CITIES = io.TextIOWrapper(zfile.open('cities.csv'))\n",
    "\n",
    "FIELDS = [\"name\", \"timeZone_label\", \"utcOffset\", \"homepage\", \"governmentType_label\",\n",
    "          \"isPartOf_label\", \"areaCode\", \"populationTotal\", \"elevation\",\n",
    "          \"maximumElevation\", \"minimumElevation\", \"populationDensity\",\n",
    "          \"wgs84_pos#lat\", \"wgs84_pos#long\", \"areaLand\", \"areaMetro\", \"areaUrban\"]\n",
    "\n",
    "def audit_file(filename, fields):\n",
    "    fieldtypes = {}\n",
    "    # Initialise fieldtypes as dictionary of empty sets (unordered collections with no duplicate elements).\n",
    "    for field in fields:\n",
    "        fieldtypes[field] = set([])\n",
    "        \n",
    "    # Skip the three unwanted header rows.\n",
    "    reader = csv.DictReader(filename)\n",
    "    for i in range(3):\n",
    "        next(reader)\n",
    "    \n",
    "    for row in reader:\n",
    "        for field in FIELDS:\n",
    "            value = row[field]\n",
    "            value_type = type(value)\n",
    "            if (value == 'NULL' or value == ''):\n",
    "                value_type = type(None)\n",
    "            elif (re.match('{', value)):\n",
    "                value_type = type([])\n",
    "            try:\n",
    "                value = int(value)\n",
    "                value_type = type(1)\n",
    "                fieldtypes[field].update([value_type])\n",
    "            except ValueError:\n",
    "                pass\n",
    "            try:\n",
    "                value = float(value)\n",
    "                value_type = type(1.1)\n",
    "                fieldtypes[field].update([value_type])\n",
    "            except ValueError:\n",
    "                pass\n",
    "            fieldtypes[field].update([value_type])\n",
    "            \n",
    "    return fieldtypes\n",
    "\n",
    "# audit_file(CITIES, FIELDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix the Name\n",
    "It would make it easier to process and query the data later, if all values for the name would be in a Python list, instead of being just a string separated with special characters. The function fix_name() will recieve a string as an input, and it has to return a list of all the names. If there is only one name, the list with have only one item in it, if the name is \"NULL\", the list should be empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with ZipFile(fname, 'r') as zfile:\n",
    "    CITIES = io.TextIOWrapper(zfile.open('cities.csv'))\n",
    "    \n",
    "def fix_name(name):\n",
    "    if name == 'NULL' or name == '':\n",
    "        return []\n",
    "    if name[0] == '{':\n",
    "        # Use a list comprehension.\n",
    "        return [x for x in name[1:-1].split('|')]\n",
    "    else:\n",
    "        return [name]\n",
    "\n",
    "def process_file(filename):\n",
    "    data = []\n",
    "    reader = csv.DictReader(filename)\n",
    "    # Skip the extra metadata.\n",
    "    for i in range(3):\n",
    "        next(reader)\n",
    "    # Process the file.\n",
    "    for line in reader:\n",
    "        # Call fix_name() function to fix the city names.\n",
    "        if 'name' in line:\n",
    "            line['name'] = fix_name(line['name'])\n",
    "        data.append(line)\n",
    "    return data\n",
    "\n",
    "# process_file(CITIES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crossfield Auditing\n",
    "There are couple of values that seem to provide the same information in different formats: \"point\" seems to be the combination of \"wgs84_pos#lat\" and \"wgs84_pos#long\". However we do not know if that is the case and should check if they are equivalent with the function check_loc(). It will recieve 3 strings, first will be the combined value of \"point\" and then the \"wgs84_pos#\" values separately. The lat and long values will be extracted from the \"point\" and will be compared to the \"wgs84_pos# values and return True or False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with ZipFile(fname, 'r') as zfile:\n",
    "    CITIES = io.TextIOWrapper(zfile.open('cities.csv'))\n",
    "\n",
    "def check_loc(point, lat, longi):\n",
    "    try:\n",
    "        p_lat, p_long = [float(x) for x in point.split(' ')]\n",
    "        return float(p_lat) == float(lat) and float(p_long) == float(longi)\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "def process_file(filename):\n",
    "    data = []\n",
    "    reader = csv.DictReader(filename)\n",
    "    # Skip the extra metadata.\n",
    "    for i in range(3):\n",
    "        next(reader)\n",
    "    # Process the file.\n",
    "    for line in reader:\n",
    "        # Call check_loc() function to check the location.\n",
    "        result = check_loc(line['point'], line['wgs84_pos#lat'], line['wgs84_pos#long'])\n",
    "        if not result:\n",
    "            print('{}: {} != {} {}'.format(line['name'], line['point'], line['wgs84_pos#lat'], line['wgs84_pos#long']))\n",
    "        data.append(line)\n",
    "\n",
    "    return data\n",
    "\n",
    "# process_file(CITIES)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
